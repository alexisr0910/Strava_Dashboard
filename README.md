# üèÉ‚Äç‚ôÇÔ∏è Strava Data Analytics Pipeline

Ce projet impl√©mente un pipeline ELT (Extract, Load, Transform) complet pour automatiser la r√©cup√©ration de mes donn√©es Strava et les transformer en donn√©es exploitables.

##  Choix Technologiques & Architecture

### Phase 1 : R√©cup√©rer des donn√©es (Extract & Load)
* **Source** : API Strava (OAuth2).
* **Outil de transport** : **Airbyte Open Source** d√©ploy√© sur Docker.

Airbyte est une plateforme d'int√©gration de donn√©es qui aide √† r√©pliquer et √† consolider facilement des donn√©es provenant de diff√©rentes sources (bases de donn√©es, API, applications SaaS). J'ai choisi cet outil car il est open source et propose un connecteur d√©j√† pr√™t pour l'API Strava. C'est une solution reconnue qui r√©pondait exactement √† mon besoin technique.

####  Installation (Airbyte)
Lors de l'installation, j'ai rencontr√© des difficult√©s li√©es √† la puissance de calcul de mon Mac. Pour optimiser l'utilisation de la RAM sur MacOS, j'ai utilis√© le mode sp√©cifique de consommation r√©duite `--low-resource-mode`.

**Commandes de gestion :**
* **D√©marrer** : `abctl local install --low-resource-mode --insecure-cookies`
* **Stopper** : `abctl local uninstall`

####  Configuration de la Source (Strava API)
* **Connexion** : Utilisation du protocole **OAuth2** en suivant la documentation officielle d'Airbyte.
* **Historique** : Param√©trage de la date de d√©but au **1er janvier 2015** afin d'importer l'int√©gralit√© de mon historique sportif.
* **S√©curit√©** : Les identifiants sensibles (`Client ID`, `Client Secret`) sont g√©r√©s uniquement dans l'interface locale d'Airbyte.

#### Configuration de la Destination (Google BigQuery)
Pour le stockage et l'analyse, j'ai choisi **Google BigQuery** comme Data Warehouse Cloud pour sa capacit√© √† g√©rer de gros volumes et sa facilit√© de connexion aux outils de visualisation.

* **Projet GCP (Google Cloud Platform)** : Cr√©ation du projet `dashboardstrava1`.
* **S√©curit√©** : Cr√©ation d'un **compte de service** sp√©cifique pour isoler les acc√®s.
* **Droits d'acc√®s** :
    * `Administrateur BigQuery` : Pour permettre √† l'outil d'√©crire les donn√©es.
    * `Administrateur Storage` : Sert de zone tampon pour fluidifier l'importation des gros volumes.
* **Dataset** : Donn√©es stock√©es dans `strava_raw` (Localisation : EU).

![img.png](img.png)

##  Param√©trage du flux (Sync Mode)

J'ai configur√© deux modes diff√©rents dans Airbyte pour optimiser le pipeline :

* **Activit√©s (`Incremental | Append + Deduped`)** :
  Ce mode permet de ne r√©cup√©rer que les nouvelles activit√©s sportives. Airbyte utilise l'identifiant unique (`id`) pour √©viter les doublons. Cela permet un chargement plus rapide et r√©duit la consommation de ressources.

* **Statistiques (`Full Refresh | Overwrite`)** :
  Pour mes records personnels et totaux globaux, j'ai choisi de remplacer int√©gralement les donn√©es √† chaque passage. Ces informations n'ayant pas d'ID unique, ce mode est n√©cessaire pour garantir des donn√©es toujours √† jour.

![img_1.png](img_1.png)
---

## Phase 2 : Transformation (Couche ODS)

L'objectif de cette √©tape est de transformer les donn√©es brutes (`strava_raw`) pour cr√©er un dataset ODS (`strava_ods`) propre et structur√©.

### Objectifs de la couche ODS
* **Nettoyage** : Passage d'un format JSON √† une structure SQL exploitable.
* **Extraction des donn√©es** : S√©lection des seules donn√©es jug√©es pertinentes (distance, vitesse, d√©nivel√©, kudos, etc.).
* **Donn√©es sensibles** : Suppression d√©finitive des coordonn√©es GPS et des identifiants personnels d√®s cette √©tape pour ne pas les stocker dans le reste du projet.

### Points techniques de la mise en place
* **V√©rification du typage** : Utilisation d'une table de test (`test_format`) pour confirmer que BigQuery et Airbyte interpr√®tent correctement les types num√©riques (`NUMERIC`, `INTEGER`).
* **Traitement du JSON** : Extraction des donn√©es imbriqu√©es pour la table `athlete_stats`. J'ai utilis√© la fonction **`CAST`** pour transformer les donn√©es textuelles issues du JSON en formats num√©riques, ce qui permet de r√©aliser des calculs par la suite.

> **Pour consulter le d√©tail du mapping, les justifications de filtrage et les √©chantillons de donn√©es, voir : [Documentation d√©taill√©e ODS](./docs/ODS/README.md)**
---

---

## Phase 3 : Mod√©lisation (Couche DWH)

L'objectif de cette derni√®re √©tape de transformation est de passer d'une structure de donn√©es "plate" √† un **mod√®le dimensionnel (Sch√©ma en √âtoile)** dans le dataset `strava_dwh`. Ce mod√®le est optimis√© pour les performances et la clart√© des analyses dans Power BI.

### Architecture du mod√®le en √©toile
Pour ce projet, j'ai structur√© les donn√©es autour d'une table de faits centrale et de plusieurs dimensions :

* **Table de Faits (`fct_activites`)** : Centralise toutes les mesures granulaires (distance, temps, vitesse).
* **Dimensions (`dim_calendar`, `dim_moment_journee`)** : Fournissent le contexte temporel et horaire pour filtrer les donn√©es.
* **Table Snapshot (`fct_global_stats`)** : Stocke les totaux historiques depuis 2015 pour servir de r√©f√©rentiel de v√©rit√©.

### Logique de transformation et calculs m√©tiers
Plusieurs transformations ont √©t√© op√©r√©es pour normaliser les indicateurs de performance :

1.  **Standardisation des unit√©s** : Conversion des donn√©es brutes en unit√©s lisibles : m√®tres vers **kilom√®tres**, m/s vers **km/h**, et secondes vers **minutes**.
2.  **Calcul de l'allure ** : Cr√©ation de la m√©trique `allure_min_km`. C'est l'indicateur principal pour la course √† pied, calcul√© via `SAFE_DIVIDE` pour garantir la stabilit√© du pipeline.
3.  **Choix du format num√©rique** : Les dur√©es sont stock√©es en format **d√©cimal** (`FLOAT64`) et non en format horaire. Ce choix technique permet √† Power BI de r√©aliser des calculs math√©matiques (moyennes, sommes) avant le formatage visuel final.
4.  **Localisation (Fran√ßais)** : Contrairement aux r√©glages par d√©faut de BigQuery (Anglais), j'ai int√©gr√© la traduction des jours et des mois directement en SQL via des instructions `CASE`. Cela permet de livrer un dataset "pr√™t √† l'emploi" pour la visualisation.

### Optimisation pour la visualisation
* **Cl√© primaire** : Cr√©ation d'un `date_id` (format `YYYYMMDD`) pour lier les activit√©s au calendrier.
* **Gestion du tri** : Ajout d'une colonne `ordre_tri` dans la dimension pour forcer Power BI √† afficher les moments de la journ√©e (Matin, Midi, Soir) chronologiquement plut√¥t qu'alphab√©tiquement.

> **Pour consulter le d√©tail de la structure du mod√®le, les formules SQL et les choix de mod√©lisation, voir : [Documentation d√©taill√©e DWH](./docs/DWH/README.md)**
---

## Pistes d'am√©lioration

Ce projet constitue une **PoC (Proof of Concept)** solide qui d√©montre la viabilit√© du flux. Le pipeline est actuellement **semi-automatique** car il d√©pend d'un environnement local, mais plusieurs axes permettraient de le passer au niveau industriel :

### 1. Automatisation
Actuellement, le pipeline d√©pend d'Airbyte tournant sur mon Mac (Docker).
* **Am√©lioration** : D√©ployer Airbyte sur une instance et utiliser les **Scheduled Queries** de BigQuery. Cela permettrait une synchronisation et une transformation des donn√©es totalement autonomes durant la nuit, sans d√©pendance mat√©rielle.

### 2. Monitoring et Alerting
Le suivi du pipeline n√©cessite aujourd'hui une v√©rification visuelle apr√®s chaque ex√©cution.
* **Am√©lioration** : Mettre en place un syst√®me de notifications (Email) pour √™tre alert√© en cas d'√©chec de la synchronisation ou d'une erreur SQL.
* **R√©f√©rence professionnelle** : Cette m√©thodologie est celle que j'applique dans le cadre de mon alternance au CHU. Chaque script de traitement g√©n√®re un fichier de log d√©taill√©. Ces fichiers sont ensuite parcourus par un automate qui remonte par mail un rapport d'√©tat chaque matin, permettant de valider le bon d√©roulement des flux nocturnes ou d'intervenir rapidement en cas d'anomalie.

### 3. Orchestration
Les transformations SQL sont d√©clench√©es manuellement de mani√®re ind√©pendante.
* **Am√©lioration** : Utiliser un orchestrateur pour g√©rer les d√©pendances (ex: ne pas lancer le DWH si l'ODS a √©chou√©).
