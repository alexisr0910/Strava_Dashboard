# üèÉ‚Äç‚ôÇÔ∏è Strava Data Analytics Pipeline

Ce projet impl√©mente un pipeline ELT (Extract, Load, Transform) complet pour automatiser la r√©cup√©ration de mes donn√©es Strava et les transformer en donn√©es exploitables.

##  Choix Technologiques & Architecture

### Phase 1 : R√©cup√©rer des donn√©es (Extract & Load)
* **Source** : API Strava (OAuth2).
* **Outil de transport** : **Airbyte Open Source** d√©ploy√© sur Docker.

Airbyte est une plateforme d'int√©gration de donn√©es qui aide √† r√©pliquer et √† consolider facilement des donn√©es provenant de diff√©rentes sources (bases de donn√©es, API, applications SaaS). J'ai choisi cet outil car il est open source et propose un connecteur d√©j√† pr√™t pour l'API Strava. C'est une solution reconnue qui r√©pondait exactement √† mon besoin technique.

####  Installation (Airbyte)
Lors de l'installation, j'ai rencontr√© des difficult√©s li√©es √† la puissance de calcul de mon Mac. Pour optimiser l'utilisation de la RAM sur MacOS, j'ai utilis√© le mode sp√©cifique de consommation r√©duite `--low-resource-mode`.

**Commandes de gestion :**
* **D√©marrer** : `abctl local install --low-resource-mode --insecure-cookies`
* **Stopper** : `abctl local uninstall`

####  Configuration de la Source (Strava API)
* **Connexion** : Utilisation du protocole **OAuth2** en suivant la documentation officielle d'Airbyte.
* **Historique** : Param√©trage de la date de d√©but au **1er janvier 2015** afin d'importer l'int√©gralit√© de mon historique sportif.
* **S√©curit√©** : Les identifiants sensibles (`Client ID`, `Client Secret`) sont g√©r√©s uniquement dans l'interface locale d'Airbyte.

#### Configuration de la Destination (Google BigQuery)
Pour le stockage et l'analyse, j'ai choisi **Google BigQuery** comme Data Warehouse Cloud pour sa capacit√© √† g√©rer de gros volumes et sa facilit√© de connexion aux outils de visualisation.

* **Projet GCP (Google Cloud Platform)** : Cr√©ation du projet `dashboardstrava1`.
* **S√©curit√©** : Cr√©ation d'un **compte de service** sp√©cifique pour isoler les acc√®s.
* **Droits d'acc√®s** :
    * `Administrateur BigQuery` : Pour permettre √† l'outil d'√©crire les donn√©es.
    * `Administrateur Storage` : Sert de zone tampon pour fluidifier l'importation des gros volumes.
* **Dataset** : Donn√©es stock√©es dans `strava_raw` (Localisation : EU).

![img.png](img.png)

##  Param√©trage du flux (Sync Mode)

J'ai configur√© deux modes diff√©rents dans Airbyte pour optimiser le pipeline :

* **Activit√©s (`Incremental | Append + Deduped`)** :
  Ce mode permet de ne r√©cup√©rer que les nouvelles activit√©s sportives. Airbyte utilise l'identifiant unique (`id`) pour √©viter les doublons. Cela permet un chargement plus rapide et r√©duit la consommation de ressources.

* **Statistiques (`Full Refresh | Overwrite`)** :
  Pour mes records personnels et totaux globaux, j'ai choisi de remplacer int√©gralement les donn√©es √† chaque passage. Ces informations n'ayant pas d'ID unique, ce mode est n√©cessaire pour garantir des donn√©es toujours √† jour.

![img_1.png](img_1.png)
---

## Phase 2 : Transformation (Couche ODS)

L'objectif de cette √©tape est de transformer les donn√©es brutes (`strava_raw`) pour cr√©er un dataset ODS (`strava_ods`) propre et structur√©.

### Objectifs de la couche ODS
* **Nettoyage** : Passage d'un format JSON √† une structure SQL exploitable.
* **Extraction des donn√©es** : S√©lection des seules donn√©es jug√©es pertinentes (distance, vitesse, d√©nivel√©, kudos, etc.).
* **Donn√©es sensibles** : Suppression d√©finitive des coordonn√©es GPS et des identifiants personnels d√®s cette √©tape pour ne pas les stocker dans le reste du projet.

### Points techniques de la mise en place
* **V√©rification du typage** : Utilisation d'une table de test (`test_format`) pour confirmer que BigQuery et Airbyte interpr√®tent correctement les types num√©riques (`NUMERIC`, `INTEGER`).
* **Traitement du JSON** : Extraction des donn√©es imbriqu√©es pour la table `athlete_stats`. J'ai utilis√© la fonction **`CAST`** pour transformer les donn√©es textuelles issues du JSON en formats num√©riques, ce qui permet de r√©aliser des calculs par la suite.

> **Pour consulter le d√©tail du mapping, les justifications de filtrage et les √©chantillons de donn√©es, voir : [Documentation d√©taill√©e ODS](./docs/ODS/README.md)**
---